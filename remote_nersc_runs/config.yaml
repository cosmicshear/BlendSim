# -----------------------------------------
# - configuration for the python script
# -----------------------------------------

parallel            : on
verbose             : 3 # 0: silent except for final status and warnings | 1: minimal progress info | 2: all steps (only with one core as a representative) | 3: all steps (from all cores) -- option 2 does not work yet (TODO)
catname             : buzzard
survey              : lsst
catversion          : 2.0.0
realization         : 3
catalog             : '{catname}_v{catversion}_{realization}'
zregime             : zs
celli               : 0 # None for no bounds # zero-indexed
cellf               : 142 #0 #142 # None for no bounds # inclusive
nest                : yes
nside               : 8 # for healpix
magcut_i_lsst       : 26.0 #24.0 # I went 2 mags fainter because Blendsim might displace some very faint galaxies and combined with other galaxies (collectively) they can have imag < final_cut or so
maxNaN              : 6 #2 # maximum allowed NaN values in observed ugrizy mags per galaxy
heal_non_det        : yes # fix non-detections
flag_non_det        : 99.0 # becomes important if heal_non_det is False

# edges of the simulation
rai                 : 0
raf                 : 180 
deci                : 0
decf                : 90 
bezel               : 0.4 # degrees from the edges of the simulation
numrand             : 6000 # throws random points in the sky to catch the edge cells

transform_eps       : yes # epsilon ellipticity for epsnoise
maxe                : 0.999999999999 # throws out bad shapes
maxiter             : 100 # used in brentq for m5 fine tuning
galfwhmlim          : [0.0, 240.0] # FWHM arcsec (exclusive interval)
save_format         : 'pickle' # feather # fit (slower?) # pickle # parquet # hdf # sql # csv (slow?)
package_dir         : /global/project/projectdirs/m1727/erfanxyz_home/myprojects/packages # /global/homes/e/erfanxyz'
scratch_dir         : /global/cscratch1/sd/tyson1
output_dir          : '{scratch_dir}/projects/blending/{catname}_v{catversion}_{survey}/{zregime}nb/r{realization}'
output_fname        : '{output_dir}/{zregime}nb.{{cell}}_r{realization}.{save_format}'
load_one_chunk      : no # just load the first "chunk" of each healpix pixel for testing purposes (usually ~8K rows for Buzzard but sometimes 1 and also 11M! so not recommended)
nrows               : 0 #10000 # analyze only the first `nrows` rows for testing purposes | 0 for all rows | must set this to 0 if load_first_chunk is True
log_memory          : no
logfname            : memory_{celli}_{cellf}_r{realization}.log # if log_memory is yes
comments            : ['Shape noise: {{shape_noise}}', '{catname} realization {realization}', 'Observed values predicted for {survey} Y{{nYrObs:.2f}}', 'Point-source {{refBand}} m5={{m5}}'] # comments for the final fits file
red_cut             : Color_true_gr_des_z01 > 0.15 - 0.03 * Mag_true_r_des_z01 # eq E24 of buzzard paper # [0.185, 0.028] mine # red = (Color_true_gr_des_z01 > red_coeffs[0] - red_coeffs[1] * Mag_true_r_des_z01)
reduce_mem_usage    : no # (already did what we could) iterate through all the columns of the output dataframe and modify the data type to reduce memory usage # 0% for this data

# -----------------------------------------
# - PhotoZDC1
# -----------------------------------------

refBand          : 'LSST_i' # for psf m5 etc.
nYrObs           : None # if None, it uses depth to get that -- if set it overrides m5
depth            : {'mag': 24.0, 'nsigma': 20} # nsigma depth at mag - the mag where you expect your SNR to be ~ nsigma for point sources (by definition) in refBand
tvis             : 30.0 # 2x15 sec exposures (same for all bands)
airMass          : 1.2
sigmaSys         : 0.005
extendedSource   : on # assumes extended sources - generates appropriate theta_eff for galaxies
HLR_gal_median   : 0.27 # not convolved! # [needed if extendedSource is on] median of galaxy half light radii in arcsec - normally for refBand but buzz_ver>=1.9.2 resamples from HST F125
RandomSeed       : 1915
nVisYr           : {'LSST_u':5.6,   'LSST_g':8.0,   'LSST_r':18.4,  'LSST_i':18.4,  'LSST_z':16.0,  'LSST_y':16.0}
msky             : {'LSST_u':22.99, 'LSST_g':22.26, 'LSST_r':21.20, 'LSST_i':20.48, 'LSST_z':19.60, 'LSST_y':18.61} # sky brightness (mag/arcsec^2)
theta_eff_zenith : {'LSST_u':0.92,  'LSST_g':0.87,  'LSST_r':0.83,  'LSST_i':0.80,  'LSST_z':0.78,  'LSST_y':0.76}  # seeing (FWHM in arcsec) at zenith for point sources
gamma_LSST       : {'LSST_u':0.038, 'LSST_g':0.039, 'LSST_r':0.039, 'LSST_i':0.039, 'LSST_z':0.039, 'LSST_y':0.039}
Cm_shifted       : {'LSST_u':22.47, 'LSST_g':24.24, 'LSST_r':24.34, 'LSST_i':24.25, 'LSST_z':24.11, 'LSST_y':23.69} # set by the throughput of the instrument / shifted to account for...
km               : {'LSST_u':0.491, 'LSST_g':0.213, 'LSST_r':0.126, 'LSST_i':0.096, 'LSST_z':0.069, 'LSST_y':0.170} # the atmospheric extinction coefficient


# -----------------------------------------
# - configuration for the job scheduler
# -----------------------------------------

# use_local_node : False # if True we won't need the rest  
node_type             : compute # compute | login
jobname               : get_observed
pyfname               : '{jobname}.py' #!join [*jobname, .py]
bashfname             : '{jobname}_{celli}_{cellf}_r{realization}.sh' #!join [*jobname, '_r{realization}', .sh] # get_observed_9_13_r3
outfname              : '{jobname}_{celli}_{cellf}_r{realization}.out' # standard output and error log
errfname              : '{jobname}_{celli}_{cellf}_r{realization}.err' #!join [*jobname, '_r{realization}', .err]
conda_env             : for_erfan_py3
project               : m1727
qos                   : 'debug' #premium # NERSC
partition             : debug # is regular by default on NERSC
constraint            : haswell # or no | NERSC Cori haswell
cores_per_node        : 32 # NERSC Cori 32
hyperthreads_per_node : 2  # NERSC Cori 2 meaning twice the cores can be assumed in multithreading
tasks                 : $cellf-celli+1$                # how many tasks in total
tasks_per_node        : 10 #4                          # (max) number of tasks per node
nodes                 : $-(-tasks//tasks_per_node)$    # number of nodes used
multithreading        : off                            # activate multithreading
hyperthreading        : off                            # activate hyperthreading
cpus_per_task         : >-                             # number of cores per MPI rank -- more than 1 for multithreading codes (TODO for this first code)
                        $1 + multithreading *
                        (((1+hyperthreading*(hyperthreads_per_node-1)) *
                        cores_per_node)//tasks_per_node-1)$
runtime               : 00:29:59                       # time limit hr:min:sec
memory_max            : 0                              # ex. 120GB | 0 grants the job access to all of the memory on each node
mailtype              : ALL                            # mail events (BEGIN,END,FAIL,ALL)
email                 : nourbakhsh@ucdavis.edu         # destination email address
